{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "# import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import svm\n",
    "import chardet\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "with open('emails.csv', 'rb') as f:\n",
    "    rawdata = f.read()\n",
    "enc = chardet.detect(rawdata)\n",
    "enc = enc['encoding']\n",
    "data = pd.read_csv('emails.csv',encoding=enc, usecols=['text', 'spam'])\n",
    "data.rename(columns={'text': 'email', 'spam': 'label'}, inplace=True)\n",
    "\n",
    "def preprocess(text) :\n",
    "    \n",
    "        \n",
    "        text=re.sub(r'[^a-zA-Z\\s]','',text)\n",
    "        \n",
    "        text=text.lower()\n",
    "        text = text.replace(\"subject\",'')\n",
    "        return text\n",
    "\n",
    "data[\"email\"]=data[\"email\"].apply(preprocess)\n",
    "emails=data[\"email\"]\n",
    "emails=np.array(emails)\n",
    "labels=data[\"label\"]\n",
    "labels=np.array(labels)\n",
    "\n",
    "\n",
    "#Naive Bayes\n",
    "vectorizer = CountVectorizer(binary=True,stop_words=\"english\")\n",
    "vectorizer.fit(emails)\n",
    "train_vectors=vectorizer.transform(emails)\n",
    "train_vectors=train_vectors.toarray()\n",
    "train_vectors=np.array(train_vectors)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_spam_train=np.sum(labels==1) \n",
    "number_of_nonspam_train=np.sum(labels==0)\n",
    "total_number_train=emails.shape[0]\n",
    "prior=(number_of_spam_train+1)/(total_number_train+2)#Laplace Smoothing add vector with all onesto both spam and ham class.\n",
    "train_spam_vectors=train_vectors[labels==1]\n",
    "train_nonspam_vectors=train_vectors[labels==0]\n",
    "prob_spam=(np.sum(train_spam_vectors,axis=0)+1)/(number_of_spam_train+1)\n",
    "prob_nonspam=(np.sum(train_nonspam_vectors,axis=0)+1)/(number_of_nonspam_train+1)\n",
    "w_NB=np.log(prob_spam*(1-prob_nonspam)/(prob_nonspam*(1-prob_spam)),dtype=\"float64\")\n",
    "bias_NB=np.sum(np.log((1-prob_spam)/(1-prob_nonspam),dtype=\"float64\"))+np.log(prior/(1-prior),dtype=\"float64\")\n",
    "NB_train_predicted_label=np.full(total_number_train,0)\n",
    "for i in range(total_number_train):\n",
    "\n",
    "    sum=np.dot(train_vectors[i],w_NB)+bias_NB\n",
    "    \n",
    "    \n",
    "    if sum >= 0 :\n",
    "       \n",
    "        NB_train_predicted_label[i]=1\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(a) :\n",
    "    return 1/(1+np.exp(-a))\n",
    "vectorizer2=TfidfVectorizer(stop_words=\"english\")\n",
    "vectorizer2.fit(emails)\n",
    "LR_train_vectors=vectorizer2.transform(emails)\n",
    "LR_train_vectors=LR_train_vectors.toarray()\n",
    "LR_train_vectors=np.array(LR_train_vectors)\n",
    "W_LR=np.zeros(LR_train_vectors.shape[1])\n",
    "N=0.1\n",
    "for itr in range(100) :\n",
    "    labels_pred=sig(np.dot(LR_train_vectors,W_LR))\n",
    "    W_LR+=N*np.dot(LR_train_vectors.T,(labels-labels_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LR_train_predicted_label=np.full(total_number_train,0)\n",
    "for i in range(total_number_train):\n",
    "\n",
    "    sum=np.dot(LR_train_vectors[i],W_LR)\n",
    "    \n",
    "    \n",
    "    if sum >= 0 :\n",
    "       \n",
    "        LR_train_predicted_label[i]=1\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer3=CountVectorizer(binary=False,stop_words=\"english\")\n",
    "vectorizer3.fit(emails)\n",
    "SVM_train_vectors=vectorizer3.transform(emails)\n",
    "SVM_train_vectors=SVM_train_vectors.toarray()\n",
    "SVM_train_vectors=np.array(SVM_train_vectors)\n",
    "svm_classifier=svm.LinearSVC(C=1,max_iter=10000,dual=False)\n",
    "svm_classifier.fit(SVM_train_vectors,labels)\n",
    "SVM_train_predictions=svm_classifier.predict(SVM_train_vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes train_accuracy   99.03980446927375\n",
      "Logistic Regression train_accuaracy   100.0\n",
      "SVM train_accuaracy   100.0\n"
     ]
    }
   ],
   "source": [
    "acc=np.sum(NB_train_predicted_label==labels)/total_number_train\n",
    "print(\"Naive Bayes train_accuracy  \",acc*100) \n",
    "LR_acc=np.sum(LR_train_predicted_label==labels)/total_number_train\n",
    "print(\"Logistic Regression train_accuaracy  \",LR_acc*100)\n",
    "SVM_acc=np.sum(SVM_train_predictions==labels)/total_number_train\n",
    "print(\"SVM train_accuaracy  \",SVM_acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=[f for f in os.listdir('test1') if f.endswith('.txt')]\n",
    "predicted_label_NB=np.zeros(len(files))\n",
    "predicted_label_LR=np.zeros(len(files))\n",
    "predicted_label_SVM=np.zeros(len(files))\n",
    "for i, file in enumerate(files):\n",
    "    with open(os.path.join('test1', file), 'r') as f:\n",
    "        email = f.read()\n",
    "\n",
    "    # Preprocess the email\n",
    "    email = preprocess(email)\n",
    "\n",
    "    # Transform the email into features\n",
    "    test_vector_NB = vectorizer.transform([email]).toarray()\n",
    "    test_vector_LR = vectorizer2.transform([email]).toarray()\n",
    "    test_vector_SVM = vectorizer3.transform([email]).toarray()\n",
    "    sum1=np.dot(test_vector_NB,w_NB)+bias_NB\n",
    "    sum2 = np.dot(test_vector_LR, W_LR)\n",
    "\n",
    "    if sum1 >= 0:\n",
    "        predicted_label_NB[i] = 1\n",
    "    if sum2 >= 0:\n",
    "        predicted_label_LR[i] = 1\n",
    "    predicted_label_SVM[i]=svm_classifier.predict(test_vector_SVM)[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR :  [0 1 0 1 0 1 0 1 0 1]\n",
      "NB :  [0 1 0 1 0 1 0 1 0 1]\n",
      "SVM :  [0 1 0 1 0 1 0 1 0 1]\n",
      "Final predictions for test emails :  [0 1 0 1 0 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"LR : \",predicted_label_LR.astype(int))\n",
    "print(\"NB : \",predicted_label_NB.astype(int))\n",
    "print(\"SVM : \",predicted_label_SVM.astype(int))\n",
    "Final_predicted_label_for_test_emails=predicted_label_NB+predicted_label_LR+predicted_label_SVM\n",
    "Final_predicted_label_for_test_emails=np.where(Final_predicted_label_for_test_emails>=2,1,0)\n",
    "print(\"Final predictions for test emails : \",Final_predicted_label_for_test_emails)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
